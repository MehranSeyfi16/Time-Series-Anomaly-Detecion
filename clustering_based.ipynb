{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 21:33:36.619701: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-12 21:33:36.622338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-12 21:33:36.622351: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import sys, os\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL, seasonal_decompose\n",
    "\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.suod import SUOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.copod import COPOD\n",
    "\n",
    "from adtk.visualization import plot\n",
    "from adtk.detector import AutoregressionAD, QuantileAD, InterQuartileRangeAD, GeneralizedESDTestAD, PersistAD, LevelShiftAD, VolatilityShiftAD, PcaAD, MinClusterDetector, SeasonalAD\n",
    "from adtk.transformer import ClassicSeasonalDecomposition\n",
    "from adtk.data import validate_series\n",
    "from adtk.metrics import iou\n",
    "from adtk.pipe import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outlier(predicted_df):\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    outlier_points = predicted_df.loc[predicted_df['prediction'] == 1] #anomaly\n",
    "    ax.plot(predicted_df.index, predicted_df['value'], color='blue', label = 'Normal')\n",
    "    ax.scatter(outlier_points.index, outlier_points['value'], color='red', label = 'Anomaly')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(original_df, predicted_df):\n",
    "    print(\"F1 Score:\", f1_score(original_df['label'], predicted_df['prediction']))\n",
    "    print(\"Recall:\", recall_score(original_df['label'], predicted_df['prediction']))\n",
    "    print(\"Precision:\", precision_score(original_df['label'], predicted_df['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df = df.set_index('timestamp')\n",
    "    df = df.asfreq(freq='T')\n",
    "    df = df.interpolate()\n",
    "    df['label'] = df.label.astype(int)\n",
    "\n",
    "    df['lag_1'] = df['value'].shift(1)\n",
    "    df['lag_2'] = df['value'].shift(2)\n",
    "    df['lag_3'] = df['value'].shift(3)\n",
    "    df['lag_4'] = df['value'].shift(4)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    decompose = STL(df['value'], period=2).fit()\n",
    "    df['resid'] = decompose.resid\n",
    "    df['trend'] = decompose.trend\n",
    "    df['seasonal'] = decompose.seasonal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all files and making the dataframe\n",
    "# df = pd.concat(map(pd.read_csv, glob.glob(os.path.join(\"./data\" , \"*.csv\"))), ignore_index= True)\n",
    "input_df = pd.read_csv('data/0.csv')\n",
    "df = process_data(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# np_scaled = scaler.fit_transform(df['value'].values.reshape(-1, 1))\n",
    "# df['scaled'] = np_scaled\n",
    "data = df[['value', 'resid', 'lag_1', 'lag_2', 'lag_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df = validate_series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_test = validate_series(df[['label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_clf = LocalOutlierFactor()\n",
    "lof_clf.fit(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_prediction_df = data.copy()\n",
    "lof_prediction_df['prediction'] = lof_clf.predict(data)\n",
    "lof_prediction_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outlier(lof_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, lof_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copod_clf = COPOD(0.06)\n",
    "copod_clf.fit(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suod_prediction_df = data.copy()\n",
    "suod_prediction_df['prediction'] = copod_clf.predict(data)\n",
    "suod_prediction_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outlier(suod_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, suod_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_clf = joblib.load('xgb_detector.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_clf = XGBOD(n_jobs=4)\n",
    "# for i in np.array_split(validate_df, 6):\n",
    "#     xgb_clf.fit(i.drop('label', axis=1), i['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_prediction_df = data.copy()\n",
    "# xgb_prediction_df['score'] = xgb_clf.decision_scores_ # outlier score\n",
    "# ae_prediction_df['prediction'] = np.where(ae_prediction_df['score'] < 4.8, 0, 1)\n",
    "# xgb_prediction_df['prediction'] = xgb_clf.predict(data.drop('label', axis=1))\n",
    "# xgb_prediction_df['prediction'].value_counts()\n",
    "# df['label'].value_counts()\n",
    "# ae_prediction_df.groupby('prediction').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_outlier(xgb_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_metrics(df, xgb_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = float(.03)\n",
    "if_model =  IsolationForest(contamination=outliers_fraction)\n",
    "if_model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_prediction_df = df.copy()\n",
    "if_prediction_df['anomaly'] = if_model.predict(data)\n",
    "if_prediction_df['prediction'] = np.where(if_prediction_df['anomaly']==-1, 1, 0)\n",
    "if_prediction_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outlier(if_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, if_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = float(0.03)\n",
    "knn_model =  KNN(contamination=outliers_fraction)\n",
    "knn_model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prediction_df = df.copy()\n",
    "knn_prediction_df['anomaly'] = knn_model.predict(data)\n",
    "knn_prediction_df['prediction'] = np.where(knn_prediction_df['anomaly']==1, 1, 0)\n",
    "knn_prediction_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outlier(knn_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, knn_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoregressionAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_ad = AutoregressionAD(n_steps=60, step_size=1, c=6.0)\n",
    "anomalies = autoregression_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, ts_markersize=1, anomaly_color='red', anomaly_tag=\"marker\", anomaly_markersize=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuantileAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_ad = QuantileAD(high=0.999, low=0.001)\n",
    "anomalies = quantile_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_markersize=5, anomaly_color='red', anomaly_tag=\"marker\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InterQuartileRangeAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_ad = InterQuartileRangeAD(c=5)\n",
    "anomalies = iqr_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_markersize=5, anomaly_color='red', anomaly_tag=\"marker\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneralizedESDTestAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esd_ad = GeneralizedESDTestAD(alpha=0.5)\n",
    "anomalies = esd_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_markersize=5, anomaly_color='red', anomaly_tag=\"marker\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PersistAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_ad = PersistAD(c=5.0, side='positive')\n",
    "anomalies = persist_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By default, PersistAD only check one previous value, which is good at capturing additive anomaly in short-term scale, but not in long-term scale because it is too near-sighted. In the following example, it fails to capture meaningful drops of price in a longer time scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_ad = PersistAD(c=2.5, side='both', window=20)\n",
    "anomalies = persist_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies['value']==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, anomaly_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LevelShiftAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_shift_ad = LevelShiftAD(c=6.0, side='both', window=5)\n",
    "anomalies = level_shift_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies.iloc[:, 0]==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, anomaly_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VolatilityShiftAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_shift_ad = VolatilityShiftAD(c=6.0, side='positive', window=30)\n",
    "anomalies = volatility_shift_ad.fit_detect(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies.iloc[:, 0]==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(validate_df, anomaly=anomalies, anomaly_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinClusterDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is more used in multivariate timeseries\n",
    "min_cluster_detector = MinClusterDetector(KMeans(n_clusters=3))\n",
    "anomalies = min_cluster_detector.fit_detect(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_color='red', anomaly_alpha=0.3, curve_group='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PcaAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ad = PcaAD(k=2, c=3.0)\n",
    "anomalies = pca_ad.fit_detect(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, anomaly=anomalies, ts_linewidth=1, ts_markersize=3, anomaly_color='red', anomaly_alpha=0.3, curve_group='all');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adtk.pipe import Pipeline\n",
    "from adtk.transformer import ClassicSeasonalDecomposition\n",
    "steps = [\n",
    "    (\"deseasonal\", ClassicSeasonalDecomposition()),\n",
    "    (\"quantile_ad\", QuantileAD(high=0.95, low=0.05))\n",
    "]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = validate_series(s)\n",
    "anomalies = pipeline.fit_detect(validate_df)\n",
    "plot(validate_df, anomaly=anomalies, ts_markersize=1, anomaly_markersize=2, anomaly_tag=\"marker\", anomaly_color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['prediction'] = np.where(anomalies==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df, anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.detectors.outlier import OutlierDetector\n",
    "\n",
    "ts_outlierDetection = OutlierDetector(validate_df, 'additive') # call OutlierDetector\n",
    "ts_outlierDetection.detector() # apply OutlierDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_outlierDetection.outliers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts_outliers_removed = ts_outlierDetection.remover(interpolate = False) # No interpolation\n",
    "air_passengers_ts_outliers_interpolated = ts_outlierDetection.remover(interpolate = True) # With interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8), nrows=1, ncols=2)\n",
    "air_passengers_ts_outliers_removed.to_dataframe().plot(x = 'time',y = 'y_0', ax= ax[0])\n",
    "ax[0].set_title(\"Outliers Removed : No interpolation\")\n",
    "air_passengers_ts_outliers_interpolated.to_dataframe().plot(x = 'time',y = 'y_0', ax= ax[1])\n",
    "ax[1].set_title(\"Outliers Removed : With interpolation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyfbad Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# from plotly.offline import iplot\n",
    "# from pyfbad.data import database as db\n",
    "# from pyfbad.models import models as md\n",
    "# from pyfbad.features import create_feature as cf\n",
    "# from pyfbad.notification import notifications as ntf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0cf53528eda0cb4bf223c9d630c850e13d0e5d45b6f3ca080b7ff6c56946f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
